@article{PRIETO2023128,
title = {Information extraction in handwritten historical logbooks},
journal = {Pattern Recognition Letters},
volume = {172},
pages = {128-136},
year = {2023},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2023.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S016786552300185X},
author = {Jose Ramón Prieto and José Andrés and Emilio Granell and Joan Andreu Sánchez and Enrique Vidal},
keywords = {Structured handwritten documents, Information extraction, Neural networks},
abstract = {Document Image Understanding is a demanding Pattern Recognition problem that requires complex recognition models. This problem is even more difficult for document images with complicated layouts like tables, where the reading order is often intrinsically ambiguous, and consequently, the context is generally ambiguous as well. In this paper, we compare two machine learning approaches for extracting information in pre-printed historical tables with handwritten information. We analyze the performance of each approach at each step of the extraction process over different corpora, up to a realistic scenario where documents with different table layouts written by different hands are used. The results are good in general and show that a model based on Multilayer Perceptrons yields better results on more homogeneous documents, while another model based on Graph Neural Networks generalizes better on heterogeneous corpora.}
}